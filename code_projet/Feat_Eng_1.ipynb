{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering : part.1\n",
    "\n",
    "***Ce script a pour but de charger, de traiter et de sauvegarder les données brutes que nous avons à disposition.***  \n",
    "Les données se décomposent de la manière suivante : \n",
    "- Une base de donnée par année enregistrant toutes les transactions des donations\n",
    "- Une base de donnée des contacts de l'ONG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Changement des options\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement et lecture des données\n",
    "On lit les données préalablement enregistrées dans le dossier 'PATH_DATA'.  \n",
    "Cette opération peut prendre un peu de temps en raison du volume des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers les données, par défaut '../data'\n",
    "PATH_DATA = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMERO_LOT</th>\n",
       "      <th>DATE_DE_RECEPTION</th>\n",
       "      <th>ID_CONTACT</th>\n",
       "      <th>MONTANT_MOUVEMENT</th>\n",
       "      <th>CAM_CODE</th>\n",
       "      <th>OPERATION</th>\n",
       "      <th>SEGMENT</th>\n",
       "      <th>MOUVEMENT_ID</th>\n",
       "      <th>OFT_CODE</th>\n",
       "      <th>MODE_DE_PAIEMENT</th>\n",
       "      <th>MONTANT_VENTILATION</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VENTILATION_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2415602.0</th>\n",
       "      <td>29770</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>713843</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>1116673.0</td>\n",
       "      <td>DON</td>\n",
       "      <td>PRE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415603.0</th>\n",
       "      <td>29770</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>818435</td>\n",
       "      <td>7.0</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>1116674.0</td>\n",
       "      <td>DON</td>\n",
       "      <td>PRE</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415604.0</th>\n",
       "      <td>29770</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>811465</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>1116675.0</td>\n",
       "      <td>DON</td>\n",
       "      <td>PRE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415605.0</th>\n",
       "      <td>29770</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>818439</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>1116676.0</td>\n",
       "      <td>DON</td>\n",
       "      <td>PRE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415606.0</th>\n",
       "      <td>29770</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>818443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>1116677.0</td>\n",
       "      <td>DON</td>\n",
       "      <td>PRE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Oui</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NUMERO_LOT DATE_DE_RECEPTION  ID_CONTACT  MONTANT_MOUVEMENT  \\\n",
       "VENTILATION_ID                                                                \n",
       "2415602.0            29770        2014-01-10      713843               10.0   \n",
       "2415603.0            29770        2014-01-10      818435                7.0   \n",
       "2415604.0            29770        2014-01-10      811465               10.0   \n",
       "2415605.0            29770        2014-01-10      818439               10.0   \n",
       "2415606.0            29770        2014-01-10      818443                0.0   \n",
       "\n",
       "               CAM_CODE OPERATION SEGMENT  MOUVEMENT_ID OFT_CODE  \\\n",
       "VENTILATION_ID                                                     \n",
       "2415602.0            PA        PA      PA     1116673.0      DON   \n",
       "2415603.0            PA        PA      PA     1116674.0      DON   \n",
       "2415604.0            PA        PA      PA     1116675.0      DON   \n",
       "2415605.0            PA        PA      PA     1116676.0      DON   \n",
       "2415606.0            PA        PA      PA     1116677.0      DON   \n",
       "\n",
       "               MODE_DE_PAIEMENT  MONTANT_VENTILATION   RF  \n",
       "VENTILATION_ID                                             \n",
       "2415602.0                   PRE                 10.0  Oui  \n",
       "2415603.0                   PRE                  7.0  Oui  \n",
       "2415604.0                   PRE                 10.0  Oui  \n",
       "2415605.0                   PRE                 10.0  Oui  \n",
       "2415606.0                   PRE                  0.0  Oui  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture des données\n",
    "def read_dons(data_filepath):\n",
    "    \"\"\"\n",
    "    Lit la base de donnée des dons dans le répertoire 'data_filepath'\n",
    "    \"\"\"\n",
    "    dons2014 = pd.read_excel(os.path.join(data_filepath,'Dons_2014.xlsx'))\n",
    "    dons2015 = pd.read_excel(os.path.join(data_filepath,'Dons_2015.xlsx'))\n",
    "    dons2016 = pd.read_excel(os.path.join(data_filepath,'Dons_2016.xlsx'))\n",
    "    dons2017 = pd.read_excel(os.path.join(data_filepath,'Dons_2017.xlsx'))\n",
    "    dons2018 = pd.read_excel(os.path.join(data_filepath,'Dons_2018.xlsx'))\n",
    "    dons = pd.concat([dons2014, dons2015, dons2016, dons2017, dons2018])\n",
    "    \n",
    "    dons_columns = ['NUMERO_LOT', 'DATE_DE_RECEPTION', 'ID_CONTACT', \n",
    "                    'MONTANT_MOUVEMENT', 'CAM_CODE', 'OPERATION', 'SEGMENT',\n",
    "                    'MOUVEMENT_ID', 'VENTILATION_ID', 'OFT_CODE', 'MODE_DE_PAIEMENT',\n",
    "                    'MONTANT_VENTILATION', 'RF']\n",
    "    dons.columns = dons_columns\n",
    "    dons.set_index('VENTILATION_ID', inplace=True)\n",
    "    \n",
    "    return dons\n",
    "\n",
    "def read_contacts(data_filepath):\n",
    "    \"\"\"\n",
    "    Lit la base de données contacts dans le répertoire 'data_filepath'\n",
    "    On extrait également le \"SEGMENT D'ORIGINE\" en vue du cleaning des données\n",
    "    \"\"\"\n",
    "    contacts = pd.read_excel(os.path.join(data_filepath,'Tous_contacts.xlsx'), index_col=0)\n",
    "    contacts.set_index('ID_CTC', inplace=True)\n",
    "\n",
    "    contacts_columns = ['TYPE_CONTACT', 'DATE_NAISSANCE', 'DATE_CREATION', 'DECEDES',\n",
    "                        'ADRESSE_POSTALE', 'PAYS', 'EMAIL_ADRESSE', 'EMAIL', 'OPTIN', 'TELEPHONE',\n",
    "                        'STOP_TEL', 'STOP_MAILING', 'STOP_GENERAL', 'NPAI2', 'SEGMENT_ORIGINE',\n",
    "                        'NOMBRE_DONS', 'MONTANT_DONS', 'DATE_PREMIER_DON', 'DATE_DERNIER_DON',\n",
    "                        'ORIGINE_PREMIER', 'ORIGINE_DERNIER', 'MONTANT_DON_PREMIER',\n",
    "                        'MONTANT_DON_DERNIER', 'NOMBRE_DONS_ANNEE_N', 'NOMBRE_DONS_ANNEE_N1',\n",
    "                        'NOMBRE_DONS_ANNEE_N2', 'NOMBRE_DONS_ANNEE_N3', 'NOMBRE_DONS_ANNEE_N4',\n",
    "                        'MONTANT_DONS_ANNEE_N', 'MONTANT_DONS_ANNEE_N1',\n",
    "                        'MONTANT_DONS_ANNEE_N2', 'MONTANT_DONS_ANNEE_N3',\n",
    "                        'MONTANT_DONS_ANNEE_N4', 'PA_ACTIF', 'DATE_DEBUT_PA_ACTIF',\n",
    "                        'DATE_FIN_PA_ACTIF', 'CYCLE_PA_ACTIF', 'DATE_DERNIER_PA_ACTIF',\n",
    "                        'ORIGINE_PA_ACTIF', 'NOMBRE_PRELEVEMENT', 'MONTANT_PRELEVEMENT',\n",
    "                        'DATE_PREMIER_PRELEVEMENT', 'DATE_DERNIER_PRELEVEMENT', 'NOMBRE_ACHAT',\n",
    "                        'MONTANT_ACHAT_MAX', 'MONTANT_ACHAT_MIN', 'DATE_PREMIER_ACHAT',\n",
    "                        'DATE_DERNIER_ACHAT', 'NOMBRE_COTISATION', 'MONTANT_COTISATION',\n",
    "                        'DATE_PREMIERE_COTISATION', 'DATE_DERNIERE_COTISATION',\n",
    "                        'NOMBRE_PETITION', 'DATE_PREMIERE_PETITION', 'DATE_DERNIERE_PETITION']\n",
    "    contacts.columns = contacts_columns\n",
    "    \n",
    "    segment_origine = pd.read_excel(os.path.join(data_filepath, 'Tous_contacts.xlsx'), sheet_name=\"Lexique codes origine\", usecols='A:C')\n",
    "    segment_origine.set_index('SEGMENT_ORIGINE', inplace=True)\n",
    "    \n",
    "    return contacts, segment_origine\n",
    "\n",
    "def read_mails(data_filepath):\n",
    "    \"\"\"\n",
    "    Lit la base de données mails dans le répertoire 'data_filepath'\n",
    "    \"\"\"\n",
    "    mails = pd.read_excel(os.path.join(data_filepath, 'stat_mailjet.xlsx'))\n",
    "    \n",
    "    mails_columns = ['ID', 'EMAIL', 'OPEN', 'CLICK', 'SENT', 'BOUNCE', \n",
    "                     'BLOCKED', 'SPAM', 'UNSUB', 'TOTAL']\n",
    "    mails.columns = mails_columns\n",
    "    \n",
    "    return mails\n",
    "    \n",
    "dons = read_dons(PATH_DATA)\n",
    "contacts, segment_origine = read_contacts(PATH_DATA)\n",
    "mails = read_mails(PATH_DATA)\n",
    "\n",
    "dons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traitement des données\n",
    "Pour chaque dataset (en particulier le dataset des contacts), on effectue des opérations de nettoyage de données ainsi que de création de variables permettant de faciliter l'exploitation de la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traitement des données\n",
    "def process_dons(df_dons):\n",
    "    \"\"\"\n",
    "    Traite le dataframe des dons\n",
    "    \"\"\"\n",
    "    df_dons.MONTANT_MOUVEMENT.fillna(0, inplace=True)\n",
    "    df_dons.MODE_DE_PAIEMENT.fillna('SIGN', inplace=True)\n",
    "    df_dons.dropna(inplace=True)\n",
    "    df_dons.MODE_DE_PAIEMENT.replace('CBW', 'CB', inplace=True)\n",
    "    \n",
    "    return df_dons\n",
    "\n",
    "def process_contacts(df_contacts, df_segment_origine):\n",
    "    \"\"\"\n",
    "    Traite le dataframe des contacts\n",
    "    \"\"\"\n",
    "    # Transformation des colonnes au format 'datetime'\n",
    "    df_contacts.DATE_CREATION = pd.to_datetime(df_contacts.DATE_CREATION, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_DEBUT_PA_ACTIF = pd.to_datetime(df_contacts.DATE_DEBUT_PA_ACTIF, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_DERNIER_ACHAT = pd.to_datetime(df_contacts.DATE_DERNIER_ACHAT, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_DERNIER_DON = pd.to_datetime(df_contacts.DATE_DERNIER_DON, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_DERNIER_PA_ACTIF = pd.to_datetime(df_contacts.DATE_DERNIER_PA_ACTIF, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_DERNIER_PRELEVEMENT = pd.to_datetime(df_contacts.DATE_DERNIER_PRELEVEMENT, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_DERNIERE_COTISATION = pd.to_datetime(df_contacts.DATE_DERNIERE_COTISATION, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_DERNIERE_PETITION = pd.to_datetime(df_contacts.DATE_DERNIERE_PETITION, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_FIN_PA_ACTIF = pd.to_datetime(df_contacts.DATE_FIN_PA_ACTIF, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_NAISSANCE = pd.to_datetime(df_contacts.DATE_NAISSANCE, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_PREMIER_ACHAT = pd.to_datetime(df_contacts.DATE_PREMIER_ACHAT, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_PREMIER_DON = pd.to_datetime(df_contacts.DATE_PREMIER_DON, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_PREMIER_PRELEVEMENT = pd.to_datetime(df_contacts.DATE_PREMIER_PRELEVEMENT, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_PREMIERE_COTISATION = pd.to_datetime(df_contacts.DATE_PREMIERE_COTISATION, format='%Y%m%d', errors='coerce')\n",
    "    df_contacts.DATE_PREMIERE_PETITION = pd.to_datetime(df_contacts.DATE_PREMIERE_PETITION, format='%Y%m%d', errors='coerce')\n",
    "    \n",
    "    # Traitement des données textuelles \n",
    "    df_contacts.EMAIL = df_contacts.EMAIL.str.lower().map(dict(oui=1, non=0))\n",
    "    df_contacts.DECEDES = df_contacts.DECEDES.str.lower().map(dict(oui=1, non=0)).fillna(0)\n",
    "    df_contacts.OPTIN = df_contacts.OPTIN.str.lower().map(dict(oui=1, non=0))\n",
    "    df_contacts.TELEPHONE = df_contacts.TELEPHONE.str.lower().map(dict(oui=1, non=0)).fillna(0)\n",
    "    df_contacts.ADRESSE_POSTALE = df_contacts.ADRESSE_POSTALE.str.lower().map(dict(oui=1, non=0))\n",
    "    df_contacts.STOP_TEL = df_contacts.STOP_TEL.str.lower().map(dict(oui=1, non=0)).fillna(0)\n",
    "    df_contacts.STOP_MAILING = df_contacts.STOP_MAILING.str.lower().map(dict(oui=1, non=0)).fillna(0)\n",
    "    df_contacts.STOP_GENERAL = df_contacts.STOP_GENERAL.str.lower().map(dict(oui=1, non=0)).fillna(0)\n",
    "    df_contacts.NPAI2 = df_contacts.NPAI2.str.lower().map(dict(oui=1, non=0)).fillna(0)\n",
    "    \n",
    "    # Traitement des dates de naissance\n",
    "    year = df_contacts.DATE_NAISSANCE.apply(lambda x: x.year)\n",
    "    mask1 = (year < 1900) | (year > 2005)\n",
    "    mask2 = (df_contacts.DATE_NAISSANCE == datetime(1970, 1, 1))\n",
    "    mask3 = (df_contacts.DATE_NAISSANCE == datetime(1900, 1, 1))\n",
    "    mask = (mask1 | mask2 | mask3)\n",
    "    df_contacts.loc[mask, 'DATE_NAISSANCE'] = np.nan\n",
    "    \n",
    "    # Remplissage des données manquantes\n",
    "    df_contacts.MONTANT_DONS.fillna(0, inplace=True)\n",
    "    df_contacts.MONTANT_DON_PREMIER.fillna(0, inplace=True)\n",
    "    df_contacts.MONTANT_DON_DERNIER.fillna(0, inplace=True)\n",
    "    df_contacts.MONTANT_DONS.fillna(0, inplace=True)\n",
    "    \n",
    "    # Création de nouvelles features\n",
    "    df_contacts['MORAL'] = df_contacts.TYPE_CONTACT.map(dict(MORAL=1, PHYSIQUE=0))\n",
    "    df_contacts['PHYSIQUE'] = df_contacts.TYPE_CONTACT.map(dict(MORAL=0, PHYSIQUE=1))\n",
    "    df_contacts['NEW_ADRESSE_POSTALE'] = df_contacts[['ADRESSE_POSTALE', 'NPAI2']].apply(lambda x: x[0] if x[1] == 0 else 0, axis=1)\n",
    "    df_contacts['CANAL_ACQUISITION'] = df_contacts.SEGMENT_ORIGINE.map(df_segment_origine.to_dict()[\"Canal d'acquisition\"])\n",
    "    df_contacts['CANAL_ACQUISITION_AGG'] = df_contacts.SEGMENT_ORIGINE.map(df_segment_origine.to_dict()[\"Canal d'acquisition agrégé\"])\n",
    "    df_contacts['CANAL_ACQUISITION_PREMIER'] = df_contacts.ORIGINE_PREMIER.map(df_segment_origine.to_dict()[\"Canal d'acquisition\"])\n",
    "    df_contacts['CANAL_ACQUISITION_AGG_PREMIER'] = df_contacts.ORIGINE_PREMIER.map(df_segment_origine.to_dict()[\"Canal d'acquisition agrégé\"])\n",
    "    df_contacts['CANAL_ACQUISITION_DERNIER'] = df_contacts.ORIGINE_DERNIER.map(df_segment_origine.to_dict()[\"Canal d'acquisition\"])\n",
    "    df_contacts['CANAL_ACQUISITION_AGG_DERNIER'] = df_contacts.ORIGINE_DERNIER.map(df_segment_origine.to_dict()[\"Canal d'acquisition agrégé\"])\n",
    "    \n",
    "    df_contacts['AGE'] = df_contacts.DATE_NAISSANCE.apply(lambda x: np.floor((datetime.today()-x).days/365))\n",
    "\n",
    "    def tranche_age(age):\n",
    "        tr = None\n",
    "        if age <= 25:\n",
    "            tr = '0-25'\n",
    "        elif 25 < age <= 45:\n",
    "            tr = '25-45'\n",
    "        elif 45 < age <= 65:\n",
    "            tr = '45-65'\n",
    "        elif age > 65:\n",
    "            tr = '65+'\n",
    "        return tr\n",
    "\n",
    "    df_contacts['TRANCHE_AGE'] = df_contacts.AGE.apply(tranche_age)\n",
    "    \n",
    "    return df_contacts\n",
    "\n",
    "dons = process_dons(dons)\n",
    "contacts = process_contacts(contacts, segment_origine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction du segment 'donateurs réguliers'\n",
    "On rappelle que les donateurs de l'ONG sont organisés selon 4 catégories dans l'ordre d'importance décroissant ci-dessous : \n",
    "- les donateurs réguliers : effectuants des donations régulières via des prélèvements automatiques\n",
    "- les donateurs occasionnels : effectuants des donations de temps à autre\n",
    "- les donateurs évènementiels : participants uniquement aux évènements de l'ONG (Trail Walker & Winter Trail)\n",
    "- les signataires : étant signés une pétition (présent dans la base de données mais n'ayant jamais donné)\n",
    "\n",
    "On extrait ici les donateurs réguliers : qui sont les donateurs sur lesquels nous allons faire nos analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelisation_donators(df_contacts, df_dons):\n",
    "    \"\"\"\n",
    "    Labellise les donateurs selon les 4 catégories ('réguliers', 'occasionnels', 'évènementiels', 'signataires')\n",
    "    \"\"\"\n",
    "    cont_oft = pd.crosstab(df_dons.ID_CONTACT, df_dons.OFT_CODE)\n",
    "    cont_cam = pd.crosstab(df_dons.ID_CONTACT, df_dons.CAM_CODE)\n",
    "\n",
    "    # Définition de chaque segment\n",
    "    signataires = cont_oft[(cont_oft.ACH == 0) & (cont_oft.COTI == 0) & (cont_oft.DON == 0)].index\n",
    "    reguliers = cont_cam[cont_cam.PA != 0].index\n",
    "    occa = cont_cam[(cont_cam.PA == 0) & (cont_cam.TW == 0) & (cont_cam.WTR == 0) & (cont_cam.EVENT == 0)].index\n",
    "    event = cont_cam[((cont_cam.TW != 0) | (cont_cam.WTR != 0) | (cont_cam.EVENT != 0)) &\n",
    "                     (cont_cam.ADH == 0) & (cont_cam.CIEL == 0) & (cont_cam.DIV == 0) &\n",
    "                     (cont_cam.F == 0) & (cont_cam.FE == 0) & (cont_cam.FMD == 0) &\n",
    "                     (cont_cam.FTEL == 0) & (cont_cam.HF == 0) & (cont_cam.IA == 0) &\n",
    "                     (cont_cam.O == 0) & (cont_cam.OI == 0) & (cont_cam.PA == 0) &\n",
    "                     (cont_cam.PART == 0) & (cont_cam.PLAQ == 0) & (cont_cam.PROGJE == 0) &\n",
    "                     (cont_cam.PROGSE == 0) & (cont_cam.PWEB == 0) & (cont_cam.RA == 0) &\n",
    "                     (cont_cam.RF == 0) & (cont_cam.SITE == 0) & (cont_cam.TEST_PET == 0) &\n",
    "                     (cont_cam.TTEL == 0) & (cont_cam.URGENCE == 0)].index\n",
    "\n",
    "    # Labelisation\n",
    "    df_contacts['REGULIER_EVENT_OCCA'] = np.nan\n",
    "    df_contacts.loc[df_contacts.index.isin(signataires), 'REGULIER_EVENT_OCCA'] = 'Signataires'\n",
    "    df_contacts.loc[df_contacts.index.isin(reguliers), 'REGULIER_EVENT_OCCA'] = 'Régulier'\n",
    "    df_contacts.loc[df_contacts.index.isin([cont for cont in occa if cont not in signataires]) , 'REGULIER_EVENT_OCCA'] = 'Occasionnel'\n",
    "    df_contacts.loc[df_contacts.index.isin([cont for cont in event if cont not in signataires]), 'REGULIER_EVENT_OCCA'] = 'Evenementiel'\n",
    "    \n",
    "    return df_contacts\n",
    "\n",
    "contacts = labelisation_donators(contacts, dons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jointure entre la base de donnée 'contact' et 'dons'\n",
    "data = dons.join(contacts, on='ID_CONTACT', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_regular_donators(df_data):\n",
    "    \"\"\"\n",
    "    Extrait les donateurs réguliers de la base de données précédentes\n",
    "    On ne garde que les colonnes utiles pour nos modèles\n",
    "    On peut finir de nettoyer ces données avec des règles propres à ce segment\n",
    "    \"\"\"\n",
    "    # Extraction des données\n",
    "    cols = ['DATE_DE_RECEPTION', 'ID_CONTACT', \n",
    "            'MONTANT_MOUVEMENT', 'CAM_CODE', 'OPERATION', 'SEGMENT', 'MOUVEMENT_ID', \n",
    "            'OFT_CODE', 'MODE_DE_PAIEMENT', 'MONTANT_VENTILATION']\n",
    "    donators_regular = df_data.loc[df_data.REGULIER_EVENT_OCCA == 'Régulier'][cols]\n",
    "    \n",
    "    # Traitement des données\n",
    "    donators_regular.DATE_DE_RECEPTION = pd.to_datetime(donators_regular.DATE_DE_RECEPTION, format='%Y-%m-%d', errors='coerce')\n",
    "    donators_regular.MONTANT_MOUVEMENT = donators_regular.MONTANT_MOUVEMENT.fillna(0)\n",
    "    donators_regular.MODE_DE_PAIEMENT = donators_regular.MODE_DE_PAIEMENT.fillna('SIGN')\n",
    "    donators_regular = donators_regular.dropna()\n",
    "    \n",
    "    return donators_regular\n",
    "\n",
    "dons_reg = extract_regular_donators(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mails(mails, contacts):\n",
    "    \"\"\"\n",
    "    Joint la base de données contacts et mails pour associer à chaque client, son comportement\n",
    "    face aux mails envoyés\n",
    "    \"\"\"\n",
    "    \n",
    "    contact_merge = contacts.loc[:, ['EMAIL_ADRESSE']]\n",
    "    contact_merge['ID_CONTACT'] = contact_merge.index\n",
    "    # Jointure des dataset\n",
    "    new_mail = mails.merge(contact_merge, right_on='EMAIL_ADRESSE', left_on='EMAIL', how='left')\n",
    "    new_mail['RATIO_CLICK'] = np.where(new_mail.SENT != 0, new_mail.CLICK / new_mail.SENT, 0) \n",
    "    new_mail['RATIO_OPEN'] = np.where(new_mail.SENT != 0, new_mail.OPEN / new_mail.SENT, 0)\n",
    "    \n",
    "    new_mail = new_mail[['ID_CONTACT', 'RATIO_CLICK', 'RATIO_OPEN']]\n",
    "    new_mail = new_mail.dropna()\n",
    "    \n",
    "    return new_mail\n",
    "\n",
    "mails = process_mails(mails, contacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarde des données\n",
    "On enregistre les données dans le même répertoire, pour pouvoir les exploiter avec les autres scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved !\n"
     ]
    }
   ],
   "source": [
    "def save_cleaned_dataframe(data_filepath, df_data, df_dons_reg, df_mails):\n",
    "    \"\"\"\n",
    "    On sauvegarde les données traitées dans le répertoire 'data_filepath':\n",
    "    - les données contacts et dons, préalablement fusionnées\n",
    "    - les données des donateurs réguliers, utiles à nos modèles\n",
    "    \"\"\"\n",
    "    df_data.to_csv(os.path.join(data_filepath, 'dons_contact_cleaned.csv'), index=False)\n",
    "    df_dons_reg.to_csv(os.path.join(data_filepath, 'dons_reguliers_cleaned.csv'), index=True)\n",
    "    df_mails.to_csv(os.path.join(data_filepath, 'mails_cleaned.csv'), index=False)\n",
    "    \n",
    "    print(\"data saved !\")\n",
    "\n",
    "save_cleaned_dataframe(PATH_DATA, data, dons_reg, mails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
